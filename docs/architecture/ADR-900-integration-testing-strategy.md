# ADR-900: Integration & Testing Strategy

## Estado
âœ… Aceptado

## Fecha
2025-12-04

## Contexto

**EPIC-RUST-10: Integration & Testing** marca la culminaciÃ³n de la migraciÃ³n Rust Phase 1. DespuÃ©s de completar Sprint 9 (VM & Bytecode), necesitamos una estrategia integral para:

1. **Integrar todos los crates** en un sistema coherente
2. **Verificar correctitud** con tests end-to-end
3. **Medir performance** vs baseline Python
4. **Garantizar memory safety** (zero leaks, zero unsafe)
5. **Documentar** la migraciÃ³n completa

### Estado Actual (Post Sprint 9)

**Crates Completados:**
- âœ… `vm` (VirtualMachine, Bytecode, GC) - 94% tests passing
- âœ… `tooling` (CLI, package manager) - bÃ¡sico
- âš ï¸ `compiler` - stub, necesita Parser â†’ Bytecode
- âš ï¸ `stdlib` - stub, necesita implementaciÃ³n
- âš ï¸ `runtime` - stub
- âš ï¸ Other crates - stubs

**Limitaciones Actuales:**
- No hay parser Vela â†’ Bytecode compiler
- No hay stdlib mÃ­nimo funcional
- No hay CLI principal que orqueste todo
- No hay tests end-to-end (source â†’ bytecode â†’ execution)

### Objetivos de Sprint 10

**Primarios:**
1. âœ… Integrar crates existentes en flujo coherente
2. âœ… Tests end-to-end (aunque sea con bytecode manual)
3. âœ… Performance benchmarks (VM vs CPython baseline)
4. âœ… Memory safety verification
5. âœ… DocumentaciÃ³n de integraciÃ³n

**Secundarios (futuro):**
- Parser Vela â†’ Bytecode (Sprint 11)
- Stdlib completo (Sprints 12-15)
- Python compatibility layer (Sprint 16+)

---

## DecisiÃ³n

### 1. Arquitectura de IntegraciÃ³n

#### 1.1 Workspace Structure

```
vela/
â”œâ”€â”€ Cargo.toml              # Workspace root
â”œâ”€â”€ vm/                     # âœ… DONE Sprint 9
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ bytecode.rs     # Bytecode format + NaN-boxing
â”‚   â”‚   â”œâ”€â”€ vm.rs           # VirtualMachine execution
â”‚   â”‚   â”œâ”€â”€ gc.rs           # Hybrid GC
â”‚   â”‚   â””â”€â”€ error.rs        # Error types
â”‚   â””â”€â”€ tests/              # 120 tests (94% passing)
â”‚
â”œâ”€â”€ compiler/               # ğŸš§ SPRINT 11 (Parser â†’ Bytecode)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lexer.rs        # Tokenizer (futuro)
â”‚   â”‚   â”œâ”€â”€ parser.rs       # AST builder (futuro)
â”‚   â”‚   â””â”€â”€ codegen.rs      # AST â†’ Bytecode (futuro)
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ stdlib/                 # ğŸš§ SPRINTS 12-15 (Standard Library)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ io.rs           # File I/O
â”‚   â”‚   â”œâ”€â”€ collections.rs  # List, Dict, Set
â”‚   â”‚   â””â”€â”€ string.rs       # String operations
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ cli/                    # ğŸš§ SPRINT 10 (Main CLI)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs         # Entry point: vela run, vela build
â”‚   â”‚   â”œâ”€â”€ repl.rs         # REPL (futuro)
â”‚   â”‚   â””â”€â”€ commands.rs     # CLI subcommands
â”‚   â””â”€â”€ Cargo.toml
â”‚
â”œâ”€â”€ runtime/                # ğŸš§ SPRINT 10 (Integration glue)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs          # Re-exports pÃºblicos
â”‚   â”‚   â””â”€â”€ integration.rs  # Glue: compiler + vm + stdlib
â”‚   â””â”€â”€ Cargo.toml
â”‚
â””â”€â”€ tests/                  # ğŸš§ SPRINT 10 (End-to-end tests)
    â”œâ”€â”€ integration/        # Source â†’ Execution tests
    â”œâ”€â”€ benchmarks/         # Performance tests vs Python
    â””â”€â”€ memory/             # Memory safety tests
```

#### 1.2 Flujo de EjecuciÃ³n (Sprint 10 MVP)

**Actualmente (Sprint 9):**
```
Manual Bytecode â†’ VirtualMachine.execute() â†’ Result<Value>
```

**Sprint 10 MVP (sin parser):**
```
Bytecode file (.velac) â†’ VirtualMachine.execute() â†’ Result<Value>
                â†‘
         (manual creation)
```

**Futuro (Sprint 11+):**
```
Source (.vela) â†’ Compiler â†’ Bytecode (.velac) â†’ VM â†’ Result<Value>
```

#### 1.3 Integration Points

**Sprint 10 se enfoca en:**
1. âœ… **VM standalone execution** (ya funciona)
2. âœ… **CLI para ejecutar bytecode** (`vela run program.velac`)
3. âœ… **Tests end-to-end con bytecode manual**
4. âœ… **Benchmarks VM vs CPython**
5. âœ… **Memory profiling**

**No incluye (Sprint 11+):**
- âŒ Parser Vela source
- âŒ Stdlib completo
- âŒ Python FFI

---

### 2. Testing Strategy

#### 2.1 Test Pyramid

```
         /\
        /  \  E2E Tests (10)       - Full programs bytecode â†’ result
       /____\
      /      \  Integration (30)   - VM + GC + Error handling
     /________\
    /          \  Unit Tests (120) - Individual modules
   /____________\
```

**DistribuciÃ³n Target Sprint 10:**
- Unit tests: 120 (âœ… done Sprint 9)
- Integration tests: 30 new
- End-to-end tests: 10 new
- **Total: 160 tests**

#### 2.2 Test Categories

**A. Unit Tests (120) - âœ… Done Sprint 9**
- Bytecode serialization: 18 tests
- GC allocation: 24 tests
- VM execution: 23 tests
- Integration: 20 tests
- Embedded: 35 tests

**B. Integration Tests (30) - ğŸš§ Sprint 10**
1. **VM + GC Integration (10 tests)**
   - Large programs with heavy allocation
   - GC triggering during execution
   - Reference cycle cleanup
   - Memory growth patterns

2. **Error Propagation (10 tests)**
   - Stack traces across call frames
   - Exception handling
   - Error recovery
   - Panic safety

3. **Multi-module Programs (10 tests)**
   - Code objects with multiple functions
   - Global variable sharing
   - Cross-module calls (futuro)

**C. End-to-End Tests (10) - ğŸš§ Sprint 10**
1. **Fibonacci (recursive)**
2. **Factorial (iterative)**
3. **Prime sieve**
4. **Sorting algorithms** (bubble, quick)
5. **Tree traversal** (DFS, BFS)
6. **String manipulation**
7. **Arithmetic expressions**
8. **Control flow** (if/else, loops)
9. **Function calls** (simple)
10. **Error cases** (division by zero, stack overflow)

#### 2.3 Performance Benchmarks

**Benchmark Suite (vs CPython 3.12):**

| Benchmark | Description | Target Speedup |
|-----------|-------------|----------------|
| `arithmetic` | 1M arithmetic ops | 5-8x |
| `fibonacci_recursive` | fib(30) | 3-5x |
| `list_operations` | 100K append/pop | 4-6x |
| `dict_operations` | 100K insert/lookup | 3-4x |
| `function_calls` | 1M function calls | 6-10x |
| `gc_stress` | Heavy allocation | 2-3x |

**Criterion.rs Configuration:**
```rust
criterion_group! {
    name = vm_benchmarks;
    config = Criterion::default()
        .sample_size(100)
        .measurement_time(Duration::from_secs(10));
    targets = 
        bench_arithmetic,
        bench_fibonacci,
        bench_list_ops,
        bench_dict_ops,
        bench_function_calls,
        bench_gc_stress
}
```

#### 2.4 Memory Safety Verification

**Tools & Techniques:**

1. **MIRI (Rust Interpreter)**
   - Detects undefined behavior
   - Verifies unsafe code (none expected)
   - Checks aliasing violations
   ```bash
   cargo +nightly miri test
   ```

2. **Valgrind (Linux/Mac)**
   - Memory leak detection
   - Invalid memory access
   - Use-after-free
   ```bash
   valgrind --leak-check=full ./target/release/vela
   ```

3. **AddressSanitizer (ASAN)**
   - Runtime memory error detection
   ```bash
   RUSTFLAGS="-Z sanitizer=address" cargo test
   ```

4. **Static Analysis**
   - Clippy lints (pedantic + nursery)
   - Cargo-deny (dependency audit)
   - Cargo-audit (security vulnerabilities)

**Memory Safety Checklist:**
- [ ] Zero memory leaks (Valgrind clean)
- [ ] Zero unsafe blocks (audit if any)
- [ ] All lifetimes correct (MIRI clean)
- [ ] No data races (thread safety)
- [ ] Panic safety (no resource leaks on panic)
- [ ] Drop implementations correct

---

### 3. CLI Integration

#### 3.1 `vela` CLI Tool

**Commands (Sprint 10 MVP):**

```bash
# Execute bytecode file
vela run program.velac

# Show version
vela --version

# Show help
vela --help
```

**Futuro (Sprint 11+):**
```bash
# Compile source to bytecode
vela build program.vela -o program.velac

# Run source directly (compile + execute)
vela run program.vela

# REPL
vela repl

# Disassemble bytecode
vela dis program.velac

# Run tests
vela test

# Package manager
vela install package-name
```

#### 3.2 CLI Implementation

**cli/src/main.rs:**
```rust
use clap::{Parser, Subcommand};
use vela_vm::{Bytecode, VirtualMachine};

#[derive(Parser)]
#[command(name = "vela")]
#[command(about = "Vela Language Runtime", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Run a bytecode file
    Run {
        /// Path to .velac bytecode file
        file: String,
    },
    /// Show version
    Version,
}

fn main() -> anyhow::Result<()> {
    let cli = Cli::parse();
    
    match cli.command {
        Commands::Run { file } => {
            let bytecode = Bytecode::from_file(&file)?;
            let mut vm = VirtualMachine::new();
            let result = vm.execute(&bytecode)?;
            println!("{}", result);
            Ok(())
        }
        Commands::Version => {
            println!("vela {}", env!("CARGO_PKG_VERSION"));
            Ok(())
        }
    }
}
```

---

### 4. Performance Targets

#### 4.1 Baseline: CPython 3.12

**Mediciones actuales (Python):**
- Arithmetic ops: ~50ns/op
- Function calls: ~200ns/call
- List append: ~100ns/op
- Dict insert: ~150ns/op
- GC overhead: ~10-15%

**Target Vela VM (Sprint 10):**
- Arithmetic ops: <10ns/op (5x faster)
- Function calls: <40ns/call (5x faster)
- List append: <20ns/op (5x faster)
- Dict insert: <50ns/op (3x faster)
- GC overhead: <5%

#### 4.2 Optimization Strategy

**Phase 1 (Sprint 10): Baseline Performance**
- âœ… Stack-based bytecode interpreter
- âœ… NaN-boxing value representation
- âœ… Hybrid GC (RC + cycle detection)
- Target: 3-5x faster than CPython

**Phase 2 (Sprint 16+): Optimizations**
- ğŸš§ Inline caching (method dispatch)
- ğŸš§ Type specialization (monomorphization)
- ğŸš§ Constant folding
- ğŸš§ Dead code elimination
- Target: 5-10x faster

**Phase 3 (Sprint 20+): JIT Compilation**
- ğŸš§ Cranelift JIT backend
- ğŸš§ Hot path detection
- ğŸš§ Tiered compilation
- Target: 10-20x faster

---

### 5. Documentation Strategy

#### 5.1 Documentation Structure

```
docs/
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ ADR-801-vm-architecture.md        # âœ… Done Sprint 9
â”‚   â”œâ”€â”€ ADR-900-integration-strategy.md   # âœ… This document
â”‚   â””â”€â”€ ADR-XXX-future-decisions.md
â”‚
â”œâ”€â”€ guides/
â”‚   â”œâ”€â”€ getting-started.md                # Quick start guide
â”‚   â”œâ”€â”€ migration-guide.md                # Python â†’ Vela
â”‚   â”œâ”€â”€ performance-guide.md              # Optimization tips
â”‚   â””â”€â”€ contributor-guide.md              # How to contribute
â”‚
â”œâ”€â”€ reference/
â”‚   â”œâ”€â”€ bytecode-format.md                # Bytecode specification
â”‚   â”œâ”€â”€ vm-internals.md                   # VM implementation details
â”‚   â”œâ”€â”€ gc-design.md                      # GC algorithm explanation
â”‚   â””â”€â”€ api-reference.md                  # Public API docs
â”‚
â”œâ”€â”€ tutorials/
â”‚   â”œâ”€â”€ 01-hello-world.md
â”‚   â”œâ”€â”€ 02-control-flow.md
â”‚   â”œâ”€â”€ 03-functions.md
â”‚   â””â”€â”€ 04-advanced.md
â”‚
â””â”€â”€ releases/
    â”œâ”€â”€ sprint-9.md                       # âœ… Done
    â””â”€â”€ sprint-10.md                      # ğŸš§ This sprint
```

#### 5.2 Documentation Priorities Sprint 10

**Must Have:**
1. âœ… Integration architecture (this ADR)
2. ğŸš§ Getting started guide (how to build & run)
3. ğŸš§ Bytecode format reference
4. ğŸš§ Performance benchmark results
5. ğŸš§ Memory safety verification report

**Nice to Have:**
- Migration guide Python â†’ Vela
- VM internals deep dive
- GC design explanation
- Tutorial series

---

### 6. Compatibility Layer (Futuro - Sprint 16+)

**Python Interop via PyO3:**

```rust
use pyo3::prelude::*;

#[pyclass]
struct VelaVM {
    vm: VirtualMachine,
}

#[pymethods]
impl VelaVM {
    #[new]
    fn new() -> Self {
        VelaVM { vm: VirtualMachine::new() }
    }
    
    fn execute(&mut self, bytecode_path: &str) -> PyResult<PyObject> {
        let bytecode = Bytecode::from_file(bytecode_path)?;
        let result = self.vm.execute(&bytecode)?;
        // Convert Vela Value â†’ Python object
        Ok(value_to_pyobject(result))
    }
}

#[pymodule]
fn vela(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<VelaVM>()?;
    Ok(())
}
```

**Uso desde Python:**
```python
import vela

vm = vela.VelaVM()
result = vm.execute("program.velac")
print(result)
```

---

## Consecuencias

### Positivas

1. **IntegraciÃ³n clara**: Workspace coherente con responsabilidades bien definidas
2. **Testing robusto**: 160 tests cubriendo unit, integration, end-to-end
3. **Performance medible**: Benchmarks sistemÃ¡ticos vs CPython
4. **Memory safety garantizada**: MÃºltiples herramientas de verificaciÃ³n
5. **DocumentaciÃ³n completa**: Facilita onboarding y contribuciones
6. **Escalabilidad**: Arquitectura preparada para Parser (Sprint 11) y Stdlib (12-15)

### Negativas

1. **No hay parser aÃºn**: Sprint 10 solo ejecuta bytecode manual
2. **Stdlib mÃ­nimo**: Sin I/O, collections avanzadas, etc.
3. **Single-threaded**: Concurrency en sprints futuros
4. **No Python FFI**: Compatibility layer pospuesto

### Trade-offs

**Decidimos priorizar:**
- âœ… VM robusto y testeado (base sÃ³lida)
- âœ… Performance measurement desde inicio
- âœ… Memory safety verification exhaustiva

**En lugar de:**
- âŒ Parser completo (Sprint 11)
- âŒ Stdlib rica (Sprints 12-15)
- âŒ Python compatibility (Sprint 16+)

**RazÃ³n:** Es mejor tener un VM pequeÃ±o y correcto que un sistema grande y bugueado.

---

## Alternativas Consideradas

### Alternativa 1: "Big Bang" Integration

**DescripciÃ³n:** Implementar todo en Sprint 10 (Parser + Stdlib + VM + CLI).

**Pros:**
- Sistema completo mÃ¡s rÃ¡pido
- Demo end-to-end desde source

**Cons:**
- Alto riesgo de bugs
- Testing insuficiente
- Deuda tÃ©cnica acumulada

**DecisiÃ³n:** âŒ Rechazada - Preferimos iteraciÃ³n incremental.

### Alternativa 2: Parser primero, Testing despuÃ©s

**DescripciÃ³n:** Sprint 10 para Parser, Sprint 11 para Testing.

**Pros:**
- Demo mÃ¡s atractivo (source â†’ execution)

**Cons:**
- VM sin validar adecuadamente
- Performance desconocida
- Memory issues no detectados

**DecisiÃ³n:** âŒ Rechazada - Testing es crÃ­tico para calidad.

### Alternativa 3: Solo Testing, sin integraciÃ³n CLI

**DescripciÃ³n:** Sprint 10 solo para tests, sin CLI.

**Pros:**
- MÃ¡xima cobertura de tests
- VM extremadamente robusto

**Cons:**
- No hay forma de usar Vela desde CLI
- DifÃ­cil demo para stakeholders

**DecisiÃ³n:** âŒ Rechazada - CLI mÃ­nimo es necesario para usabilidad.

---

## Referencias

- **ADR-801**: VM Architecture (Sprint 9)
- **EPIC-RUST-10**: Integration & Testing (Roadmap)
- **Criterion.rs**: https://github.com/bheisler/criterion.rs
- **MIRI**: https://github.com/rust-lang/miri
- **PyO3**: https://pyo3.rs (futuro)

---

## ImplementaciÃ³n

### Sprint 10 Roadmap

**Week 1:**
- âœ… ADR-900 (this document)
- ğŸš§ CLI tool (`vela run`)
- ğŸš§ Integration tests (30 tests)

**Week 2:**
- ğŸš§ End-to-end tests (10 tests)
- ğŸš§ Performance benchmarks (6 benchmarks)
- ğŸš§ Memory safety verification (MIRI + Valgrind)

**Week 3:**
- ğŸš§ Documentation (guides + reference)
- ğŸš§ CI/CD pipeline (GitHub Actions)
- ğŸš§ Release sprint-10 tag

---

**ÃšLTIMA ACTUALIZACIÃ“N:** 2025-12-04  
**VERSIÃ“N:** 1.0.0  
**STATUS:** âœ… Aceptado
