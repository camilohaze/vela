# Vela Compiler Architecture Guide

## ğŸ—ï¸ Overview

El compiler de Vela estÃ¡ diseÃ±ado como un pipeline modular de anÃ¡lisis y transformaciÃ³n, siguiendo principios de diseÃ±o funcional y separaciÃ³n de responsabilidades. Esta arquitectura permite extensibilidad, testabilidad y mantenibilidad.

## ğŸ›ï¸ Architectural Principles

### 1. **Pipeline Design**
El compiler sigue un patrÃ³n de pipeline lineal donde cada etapa transforma la salida de la anterior:

```
Source Code â†’ Lexer â†’ Parser â†’ Semantic Analyzer â†’ Code Generator â†’ Bytecode
```

### 2. **Separation of Concerns**
Cada mÃ³dulo tiene una responsabilidad Ãºnica y bien definida:
- **Lexer**: AnÃ¡lisis lÃ©xico
- **Parser**: AnÃ¡lisis sintÃ¡ctico
- **Semantic**: AnÃ¡lisis semÃ¡ntico
- **Codegen**: GeneraciÃ³n de cÃ³digo

### 3. **Error Propagation**
Sistema unificado de errores que se propaga a travÃ©s del pipeline con informaciÃ³n contextual.

### 4. **Immutability**
Las estructuras de datos son inmutables donde es posible, siguiendo principios funcionales.

## ğŸ“¦ Module Architecture

### Core Modules

```
vela-compiler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs           # Punto de entrada principal
â”‚   â”œâ”€â”€ lexer.rs         # AnÃ¡lisis lÃ©xico
â”‚   â”œâ”€â”€ parser.rs        # AnÃ¡lisis sintÃ¡ctico
â”‚   â”œâ”€â”€ semantic.rs      # AnÃ¡lisis semÃ¡ntico
â”‚   â”œâ”€â”€ codegen.rs       # GeneraciÃ³n de cÃ³digo
â”‚   â”œâ”€â”€ error.rs         # Sistema de errores
â”‚   â””â”€â”€ config.rs        # ConfiguraciÃ³n
â”œâ”€â”€ Cargo.toml
â””â”€â”€ tests/
    â””â”€â”€ integration.rs   # Tests de integraciÃ³n
```

### Dependencies

```toml
[dependencies]
vela-ast = { path = "../ast" }          # Definiciones AST
vela-vm = { path = "../vm" }            # VM y bytecode
anyhow = "1.0"                          # Error handling
thiserror = "1.0"                       # Error definitions
serde = { version = "1.0", features = ["derive"] }  # Serialization
tracing = "0.1"                         # Logging
```

## ğŸ”„ Pipeline Flow

### 1. Lexical Analysis (Lexer)

**Input:** `String` (cÃ³digo fuente)
**Output:** `Vec<Token>`
**Responsibility:** Tokenizar el cÃ³digo fuente en unidades lÃ©xicas

```rust
pub struct Lexer {
    source: String,
    source_path: PathBuf,
    position: usize,
    line: usize,
    column: usize,
}

impl Lexer {
    pub fn tokenize(&mut self) -> Result<Vec<Token>, LexerError> {
        let mut tokens = Vec::new();
        while !self.is_at_end() {
            let token = self.scan_token()?;
            tokens.push(token);
        }
        tokens.push(Token::new(TokenKind::EOF, self.current_range()));
        Ok(tokens)
    }
}
```

**Key Components:**
- **State Machine**: Maneja diferentes estados lÃ©xicos (normal, string, comment)
- **Error Recovery**: ContinÃºa tokenizando despuÃ©s de errores
- **Source Location Tracking**: Mantiene posiciÃ³n precisa para errores

### 2. Syntax Analysis (Parser)

**Input:** `Vec<Token>`
**Output:** `Program` (AST)
**Responsibility:** Parsear tokens en estructura sintÃ¡ctica

```rust
pub struct Parser {
    tokens: Vec<Token>,
    current: usize,
}

impl Parser {
    pub fn parse(&mut self) -> Result<Program, ParserError> {
        let mut declarations = Vec::new();

        while !self.is_at_end() {
            let declaration = self.parse_declaration()?;
            declarations.push(declaration);
        }

        Ok(Program::new(self.tokens[0].range.clone(), declarations))
    }
}
```

**Key Components:**
- **Recursive Descent**: Parser recursivo descendente con precedencia de operadores
- **Error Recovery**: SincronizaciÃ³n despuÃ©s de errores para continuar parsing
- **AST Construction**: Construye Ã¡rbol sintÃ¡ctico abstracto

### 3. Semantic Analysis

**Input:** `Program` (AST)
**Output:** `SemanticProgram` (AST anotado)
**Responsibility:** Validar semÃ¡ntica y resolver sÃ­mbolos

```rust
pub struct SemanticAnalyzer {
    symbol_table: SymbolTable,
    scope_stack: Vec<Scope>,
    errors: Vec<SemanticError>,
}

impl SemanticAnalyzer {
    pub fn analyze(&mut self, program: &Program) -> Result<SemanticProgram, CompileError> {
        self.visit_program(program)?;
        if self.errors.is_empty() {
            Ok(SemanticProgram::from(program))
        } else {
            Err(CompileError::Semantic(self.errors.remove(0)))
        }
    }
}
```

**Key Components:**
- **Symbol Resolution**: Resuelve nombres a definiciones
- **Type Checking**: Verifica compatibilidad de tipos
- **Scope Management**: Maneja Ã¡mbitos lÃ©xicos
- **Error Collection**: Recolecta mÃºltiples errores semÃ¡nticos

### 4. Code Generation

**Input:** `SemanticProgram` (AST anotado)
**Output:** `Bytecode`
**Responsibility:** Generar bytecode ejecutable

```rust
pub struct CodeGenerator {
    bytecode: Bytecode,
    symbol_table: HashMap<String, usize>,
    functions: Vec<Function>,
}

impl CodeGenerator {
    pub fn generate_program(&mut self, program: &SemanticProgram) -> Result<Bytecode, CompileError> {
        for declaration in &program.declarations {
            self.generate_declaration(declaration)?;
        }
        Ok(self.bytecode.clone())
    }
}
```

**Key Components:**
- **Instruction Emission**: Emite instrucciones bytecode apropiadas
- **Symbol Table**: Mapea sÃ­mbolos a Ã­ndices de constantes
- **Control Flow**: Maneja saltos y bucles
- **Function Generation**: Crea definiciones de funciones

## ğŸ”— Integration Points

### With AST Module

```rust
// AST definitions shared between parser and semantic analyzer
pub mod ast {
    pub struct Program { /* ... */ }
    pub enum Declaration { /* ... */ }
    pub enum Expression { /* ... */ }
}
```

### With VM Module

```rust
// Bytecode format shared between codegen and VM
pub mod bytecode {
    pub enum Instruction { /* ... */ }
    pub struct Bytecode { /* ... */ }
}
```

## ğŸ›¡ï¸ Error Handling Architecture

### Unified Error Types

```rust
pub enum CompileError {
    Lexer(LexerError),
    Parser(ParserError),
    Semantic(SemanticError),
    Codegen(CodegenError),
}

pub struct SourceLocation {
    pub file: PathBuf,
    pub line: usize,
    pub column: usize,
    pub length: usize,
}
```

### Error Propagation

```rust
// Each pipeline stage returns Result<T, CompileError>
fn compile(source: &str) -> Result<Bytecode, CompileError> {
    let tokens = lexer.tokenize(source)?;
    let ast = parser.parse(tokens)?;
    let semantic_ast = semantic_analyzer.analyze(&ast)?;
    let bytecode = code_generator.generate(&semantic_ast)?;
    Ok(bytecode)
}
```

## âš¡ Performance Considerations

### Memory Management
- **AST Reuse**: El AST se reutiliza entre etapas cuando es posible
- **Streaming**: Procesamiento en streaming para archivos grandes
- **Lazy Evaluation**: EvaluaciÃ³n diferida de expresiones constantes

### Optimization Opportunities
- **Constant Folding**: EvaluaciÃ³n de expresiones constantes en compile-time
- **Dead Code Elimination**: EliminaciÃ³n de cÃ³digo unreachable
- **Register Allocation**: AsignaciÃ³n Ã³ptima de registros en bytecode

## ğŸ§ª Testing Architecture

### Unit Tests
Cada mÃ³dulo tiene tests unitarios independientes:
- `lexer/tests.rs` - Tests del lexer
- `parser/tests.rs` - Tests del parser
- `semantic/tests.rs` - Tests del analizador semÃ¡ntico
- `codegen/tests.rs` - Tests del generador de cÃ³digo

### Integration Tests
Tests end-to-end que verifican el pipeline completo:
- `tests/integration.rs` - Tests de integraciÃ³n completa

### Fuzz Testing
Tests de fuzzing para entradas malformadas:
- `tests/fuzz_lexer.rs` - Fuzzing del lexer
- `tests/fuzz_parser.rs` - Fuzzing del parser

## ğŸ”§ Configuration System

```rust
pub struct Config {
    pub optimization_level: OptimizationLevel,
    pub target_platform: TargetPlatform,
    pub debug_info: bool,
    pub warnings_as_errors: bool,
    pub error_format: ErrorFormat,
}

pub enum OptimizationLevel {
    None,
    Basic,
    Aggressive,
}

pub enum TargetPlatform {
    Native,
    WebAssembly,
    CrossPlatform,
}
```

## ğŸš€ Extensibility Points

### Adding New Language Features

1. **Lexer**: Agregar nuevos tokens en `TokenKind`
2. **Parser**: Extender gramÃ¡tica en mÃ©todos de parsing
3. **Semantic**: Agregar reglas de validaciÃ³n
4. **Codegen**: Implementar emisiÃ³n de bytecode

### Backend Targets

El diseÃ±o modular permite mÃºltiples backends:
- **Bytecode VM** (actual)
- **Native Code** (futuro)
- **WebAssembly** (futuro)
- **LLVM IR** (futuro)

## ğŸ“Š Metrics & Monitoring

### Compilation Metrics
- **Token Count**: NÃºmero de tokens procesados
- **AST Node Count**: TamaÃ±o del Ã¡rbol sintÃ¡ctico
- **Bytecode Size**: TamaÃ±o del bytecode generado
- **Compilation Time**: Tiempo total de compilaciÃ³n

### Error Metrics
- **Error Rate**: Errores por lÃ­nea de cÃ³digo
- **Error Types**: DistribuciÃ³n de tipos de error
- **Recovery Success**: Tasa de recuperaciÃ³n de errores

## ğŸ”— Related Documentation

- [API Reference](api-reference.md) - Referencia completa de APIs
- [User Guide](user-guide.md) - GuÃ­a para usuarios
- [Developer Guide](developer-guide.md) - GuÃ­a para desarrolladores
- [Troubleshooting](troubleshooting.md) - SoluciÃ³n de problemas

---

*DocumentaciÃ³n generada automÃ¡ticamente. Ãšltima actualizaciÃ³n: 2025-12-03*