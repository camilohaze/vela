"""
Ejemplo de uso del Test Runner de Vela

Este archivo demuestra cÃ³mo ejecutar tests automÃ¡ticamente
y generar diferentes tipos de reportes.

Jira: VELA-1130
Fecha: 2025-12-14
"""

import { describe, it, expect } from './api'
import { TestRunner, ConsoleReporter, JsonReporter, JunitReporter, HtmlReporter, runTests, addReporter } from './runner'

// Importar tests (en un sistema real, esto serÃ­a automÃ¡tico)
import './calculator_tests'

// FunciÃ³n principal para ejecutar tests
fn main() -> void {
  print("ğŸš€ Ejecutando Test Suite de Vela")
  print("=" * 50)

  // Configurar reporters adicionales
  addReporter(JsonReporter("test-results.json"))
  addReporter(JunitReporter("test-results.xml"))
  addReporter(HtmlReporter("test-results.html"))

  // Ejecutar todos los tests
  let results = runTests()

  print("\n" + "=" * 50)
  print("ğŸ“Š Resumen Final:"  print("   Total de tests: ${results.total}")
  print("   Tests pasados: ${results.passed}")
  print("   Tests fallidos: ${results.failed}")
  print("   Tiempo total: ${results.duration}ms")

  // Reporte detallado por suite
  print("\nğŸ“‹ Detalle por Suite:")
  for suiteResult in results.suiteResults {
    let status = if suiteResult.failed == 0 { "âœ…" } else { "âŒ" }
    print("   ${status} ${suiteResult.suite.name}: ${suiteResult.passed}/${suiteResult.passed + suiteResult.failed} (${suiteResult.duration}ms)")
  }

  // Generar cÃ³digo de salida basado en resultados
  if results.failed > 0 {
    print("\nâŒ Algunos tests fallaron. Revisa los reportes para mÃ¡s detalles.")
    exit(1)
  } else {
    print("\nğŸ‰ Todos los tests pasaron exitosamente!")
    exit(0)
  }
}

// FunciÃ³n para ejecutar tests con filtro
fn runFilteredTests(pattern: String) -> void {
  print("ğŸ” Ejecutando tests que coinciden con: '${pattern}'")
  print("-" * 50)

  let runner = TestRunner()
  runner.setFilter(pattern)
  runner.addReporter(ConsoleReporter())

  let results = runner.runAll()

  print("\nğŸ“Š Resultados filtrados:")
  print("   Tests encontrados: ${results.total}")
  print("   Tests pasados: ${results.passed}")
  print("   Tests fallidos: ${results.failed}")
}

// FunciÃ³n para ejecutar solo una suite especÃ­fica
fn runSuiteTests(suiteName: String) -> void {
  print("ğŸ¯ Ejecutando suite: '${suiteName}'")
  print("-" * 50)

  let runner = TestRunner()
  runner.setFilter(suiteName)
  runner.addReporter(ConsoleReporter())

  let results = runner.runAll()

  if results.total == 0 {
    print("âš ï¸  No se encontraron tests para la suite '${suiteName}'")
  }
}

// FunciÃ³n de utilidad para benchmarks
fn runBenchmarks() -> void {
  print("âš¡ Ejecutando Benchmarks")
  print("=" * 50)

  let runner = TestRunner()
  runner.setFilter("Performance")
  runner.addReporter(ConsoleReporter())

  let startTime = Date.now()
  let results = runner.runAll()
  let totalTime = Date.now() - startTime

  print("\nâ±ï¸  Benchmark completado en ${totalTime}ms")
  print("   Tests de performance: ${results.total}")
  print("   Todos pasaron: ${results.failed == 0}")
}

// FunciÃ³n para generar reporte de cobertura (placeholder)
fn generateCoverageReport() -> void {
  print("ğŸ“Š Generando Reporte de Cobertura")
  print("-" * 50)

  // En una implementaciÃ³n real, esto analizarÃ­a quÃ© lÃ­neas se ejecutaron
  print("âœ… Cobertura de lÃ­neas: 85%")
  print("âœ… Cobertura de ramas: 78%")
  print("âœ… Cobertura de funciones: 92%")

  print("\nğŸ“„ Reporte generado: coverage.html")
}

// ConfiguraciÃ³n de CI/CD
fn setupCI() -> void {
  print("ğŸ”§ Configurando entorno CI/CD")
  print("-" * 50)

  // Configurar reporters para CI
  addReporter(JunitReporter("junit-results.xml"))
  addReporter(JsonReporter("test-results.json"))

  // Configurar variables de entorno
  setEnv("VELA_TEST_MODE", "ci")
  setEnv("VELA_TEST_TIMEOUT", "30000")  // 30 segundos

  print("âœ… Reporters JUnit y JSON configurados")
  print("âœ… Variables de entorno establecidas")
}

// FunciÃ³n de ayuda para debugging
fn debugTest(testName: String) -> void {
  print("ğŸ› Debug mode para test: '${testName}'")
  print("-" * 50)

  let runner = TestRunner()
  runner.setFilter(testName)
  runner.addReporter(ConsoleReporter())

  // Modo verbose para debugging
  setEnv("VELA_TEST_VERBOSE", "true")

  let results = runner.runAll()

  if results.failed > 0 {
    print("\nğŸ” Analizando fallos...")
    for suiteResult in results.suiteResults {
      for testResult in suiteResult.results {
        if !testResult.passed {
          match testResult.error {
            Some(error) => {
              print("âŒ Error en '${testResult.description}': ${error}")
              print("   Sugerencias de debugging:")
              print("   - Verifica los valores de entrada")
              print("   - Revisa la lÃ³gica de la funciÃ³n testeada")
              print("   - Verifica que las dependencias estÃ©n inicializadas")
            }
            None => {}
          }
        }
      }
    }
  }
}

// FunciÃ³n para ejecutar tests en paralelo (si se implementa)
fn runParallelTests() -> void {
  print("ğŸ”„ Ejecutando tests en paralelo")
  print("-" * 50)

  // En una implementaciÃ³n real, esto distribuirÃ­a tests entre workers
  print("âœ… Tests distribuidos entre 4 workers")
  print("âœ… Ejecutando en paralelo...")

  let results = runTests()

  print("âœ… Tests paralelos completados")
}

// Exportar funciones para uso desde lÃ­nea de comandos
export {
  main,
  runFilteredTests,
  runSuiteTests,
  runBenchmarks,
  generateCoverageReport,
  setupCI,
  debugTest,
  runParallelTests
}

// Si se ejecuta directamente, correr main
if __name__ == "__main__" {
  main()
}